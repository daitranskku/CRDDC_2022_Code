{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ed541f",
   "metadata": {},
   "source": [
    "# Load GT & Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18faea0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import natsort\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e836e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_NAMES = ['India', 'Czech', 'Japan',\n",
    "               'Norway', 'United_States',\n",
    "               'China_MotorBike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb19d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"China_MotorBike\"\n",
    "IMAGE_DIR = \"/SSD/IEEE/data/\"+country+\"/train/images\"\n",
    "ANN_DIR = \"/SSD/IEEE/data/\"+country+\"/train/annotations/xmls\"\n",
    "SAVE_AIHUB_form_DIR = \"/SSD/IEEE/src/prepare_data/preprocessed_labels/\"+country+\"/train/annotations\"\n",
    "if not os.path.exists(SAVE_AIHUB_form_DIR): \n",
    "    os.makedirs(SAVE_AIHUB_form_DIR)\n",
    "target_cls = ['D00','D10','D20','D40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78200004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_names(IMAGE_DIR):\n",
    "    \n",
    "    file_format = ['jpg','png','JPG','PNG']\n",
    "    \n",
    "    file_names = os.listdir(IMAGE_DIR)\n",
    "    image_file_names = []\n",
    "    for file_name in tqdm(file_names):\n",
    "        if file_name.split('.')[-1] in file_format:\n",
    "            image_file_names.append(file_name)\n",
    "   \n",
    "    return natsort.natsorted(image_file_names)\n",
    "\n",
    "def get_ann_file_names(ANN_DIR):\n",
    "    \n",
    "    file_format = ['xml','json']\n",
    "    \n",
    "    file_names = os.listdir(ANN_DIR)\n",
    "    ann_file_names = []\n",
    "    for file_name in tqdm(file_names):\n",
    "        if file_name.split('.')[-1] in file_format:\n",
    "            ann_file_names.append(file_name)\n",
    "   \n",
    "    return natsort.natsorted(ann_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b75e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1977/1977 [00:00<00:00, 667697.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1977/1977 [00:01<00:00, 1328.61it/s]\n"
     ]
    }
   ],
   "source": [
    "ann_file_names = get_ann_file_names(ANN_DIR)\n",
    "\n",
    "for ann_file in tqdm(ann_file_names):\n",
    "    tree = ET.parse(os.path.join(ANN_DIR,ann_file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    if root.findtext('segmented') == '1':\n",
    "        print('Warning')\n",
    "        break\n",
    "        \n",
    "    filename = root.findtext('filename')\n",
    "    img_w = root.find('size').findtext('width')\n",
    "    img_h = root.find('size').findtext('height')\n",
    "    objs = root.findall('object')\n",
    "    \n",
    "    # load image\n",
    "    # image_path = os.path.join(IMAGE_DIR, filename)\n",
    "    # image = cv2.imread(image_path)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    gt = []\n",
    "    for obj in objs:\n",
    "        temp = {}\n",
    "\n",
    "        cls_name = obj.findtext('name')\n",
    "        temp['cls_name'] = cls_name\n",
    "        \n",
    "        bbox = obj.find('bndbox')\n",
    "        x1 = int(float(bbox.findtext('xmin')))\n",
    "        y1 = int(float(bbox.findtext('ymin')))\n",
    "        x2 = int(float(bbox.findtext('xmax')))\n",
    "        y2 = int(float(bbox.findtext('ymax')))\n",
    "        temp['bbox'] = [x1,y1,x2,y2]\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            print(f\"Box size error !: {x1, y1, x2, y2}\")\n",
    "            break\n",
    "        elif cls_name not in target_cls:\n",
    "            # print(f\"Delete class: {cls_name}\")\n",
    "            break\n",
    "        else:\n",
    "            gt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b8a892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(float(bbox.findtext('xmin')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84782aea",
   "metadata": {},
   "source": [
    "# to AIHUB form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "851c8da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1977/1977 [00:00<00:00, 550862.89it/s]\n"
     ]
    }
   ],
   "source": [
    "ann_file_names = get_ann_file_names(ANN_DIR)\n",
    "\n",
    "for idx,ann_file in enumerate(ann_file_names):\n",
    "    \n",
    "    tree = ET.parse(os.path.join(ANN_DIR,ann_file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    filename = root.findtext('filename')\n",
    "    img_w = int(root.find('size').findtext('width'))\n",
    "    img_h = int(root.find('size').findtext('height'))\n",
    "    objs = root.findall('object')\n",
    "    \n",
    "    # Declare saved json form\n",
    "    save_json = {}\n",
    "    image_dict = {}\n",
    "    image_dict['filename'] = filename\n",
    "    image_dict['resolution'] = [img_w, img_h]\n",
    "    \n",
    "    \n",
    "    annotation_dict = []\n",
    "    for obj in objs:\n",
    "        annotation_dict_temp = {}\n",
    "\n",
    "        cls_name = obj.findtext('name')\n",
    "        \n",
    "        bbox = obj.find('bndbox')\n",
    "        x1 = int(float(bbox.findtext('xmin')))\n",
    "        y1 = int(float(bbox.findtext('ymin')))\n",
    "        x2 = int(float(bbox.findtext('xmax')))\n",
    "        y2 = int(float(bbox.findtext('ymax')))\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            print(f\"Box size error !: {x1, y1, x2, y2}\")\n",
    "            pass\n",
    "        elif cls_name not in target_cls:\n",
    "            # print(f\"Delete class: {cls_name}\")\n",
    "            pass\n",
    "        else:\n",
    "            annotation_dict_temp['box'] = [x1,y1,x2,y2]\n",
    "            annotation_dict_temp['class'] = cls_name\n",
    "            annotation_dict.append(annotation_dict_temp)\n",
    "            \n",
    "    save_json['image'] = image_dict\n",
    "    save_json['annotations'] = annotation_dict\n",
    "    \n",
    "    save_path = os.path.join(SAVE_AIHUB_form_DIR, filename.split('.')[0]+'.json')\n",
    "    with open(save_path, 'w', encoding='utf-8') as make_file:\n",
    "        json.dump(save_json, make_file, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31479926",
   "metadata": {},
   "source": [
    "# Split base on ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824556f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1977/1977 [00:00<00:00, 508283.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1977"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json file\n",
    "annotations_path = SAVE_AIHUB_form_DIR # Train included test file\n",
    "\n",
    "label_file_names = get_ann_file_names(annotations_path)\n",
    "\n",
    "len(label_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6067b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1977it [00:01, 1124.29it/s]\n"
     ]
    }
   ],
   "source": [
    "file_list = label_file_names\n",
    "path = annotations_path\n",
    "\n",
    "category_list=[]\n",
    "for idx,file_name in tqdm(enumerate(file_list)):\n",
    "    with open(os.path.join(annotations_path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # categories\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        if instance[\"class\"] in category_list:\n",
    "            pass\n",
    "        else:\n",
    "            category_list.append(instance[\"class\"])\n",
    "    category_list=natsort.natsorted(category_list)\n",
    "    category_dic_count = dict.fromkeys(category_list, 0)\n",
    "    category_dic_filename = dict.fromkeys(category_list)\n",
    "    \n",
    "    for key in category_dic_filename.keys():\n",
    "        category_dic_filename[key]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91744382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D00', 'D10', 'D20', 'D40']\n",
      "{'D00': 0, 'D10': 0, 'D20': 0, 'D40': 0}\n"
     ]
    }
   ],
   "source": [
    "print(category_list)\n",
    "print(category_dic_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fdd3f",
   "metadata": {},
   "source": [
    "### Count & Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cc1e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1977it [00:01, 1820.15it/s]\n"
     ]
    }
   ],
   "source": [
    "file_list = natsort.natsorted(file_list)\n",
    "\n",
    "ban_list = []\n",
    "for idx,file_name in tqdm(enumerate(file_list)):\n",
    "\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    class_id_list = []\n",
    "    # categories\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        class_id_list.append(instance[\"class\"])\n",
    "\n",
    "\n",
    "    # print(class_id_list)\n",
    "\n",
    "    count_items = Counter(class_id_list)\n",
    "\n",
    "    # print(count_items)\n",
    "    \n",
    "    try:\n",
    "        class_id = count_items.most_common(n=1)[0][0]\n",
    "        category_dic_count[class_id]+=1\n",
    "        category_dic_filename[class_id].append(file_name)\n",
    "    except:\n",
    "        ban_list.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b3004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [] \n",
    "test = [] \n",
    "\n",
    "for key in category_dic_count.keys():\n",
    "\n",
    "    if (category_dic_count[key]):\n",
    "        temp=category_dic_filename[key]\n",
    "\n",
    "        train_temp, test_temp = train_test_split(temp, test_size=0.2)\n",
    "\n",
    "        train.extend(train_temp)\n",
    "        test.extend(test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471d4635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1977it [00:00, 1983.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'D00': 2678, 'D10': 1096, 'D20': 641, 'D40': 235}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dic_total_count = dict.fromkeys(category_list, 0)\n",
    "\n",
    "for idx,file_name in tqdm(enumerate(file_list)):\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # categories\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        category_dic_total_count[instance[\"class\"]]+=1\n",
    "        \n",
    "category_dic_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24576f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:00, 1859.66it/s]\n",
      "389it [00:00, 1038.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D00': 2142, 'D10': 870, 'D20': 512, 'D40': 189}\n",
      "{'D00': 536, 'D10': 226, 'D20': 129, 'D40': 46}\n",
      "{'D00': 2678, 'D10': 1096, 'D20': 641, 'D40': 235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dic_count = dict.fromkeys(category_list, 0)\n",
    "# val_dic_count = dict.fromkeys(category_list, 0)\n",
    "test_dic_count = dict.fromkeys(category_list, 0)\n",
    "\n",
    "for idx,file_name in tqdm(enumerate(train)):\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # categories\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        train_dic_count[instance[\"class\"]]+=1\n",
    "        \n",
    "for idx,file_name in tqdm(enumerate(test)):\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # categories\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        test_dic_count[instance[\"class\"]]+=1\n",
    "        \n",
    "print(train_dic_count)\n",
    "# print(val_dic_count)\n",
    "print(test_dic_count)\n",
    "print(category_dic_total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf371d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a33fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoires part of coco\n",
    "category_dic_list=[]\n",
    "\n",
    "for idx, label in enumerate(category_list):\n",
    "    category_dic={}\n",
    "    category_dic[\"id\"]=idx+1\n",
    "    category_dic[\"name\"]=label\n",
    "    category_dic[\"supercategory\"]='crack'\n",
    "    category_dic_list.append(category_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ffdaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'D00', 'supercategory': 'crack'},\n",
       " {'id': 2, 'name': 'D10', 'supercategory': 'crack'},\n",
       " {'id': 3, 'name': 'D20', 'supercategory': 'crack'},\n",
       " {'id': 4, 'name': 'D40', 'supercategory': 'crack'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c7f41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/SSD/IEEE/src/prepare_data/train_labels/\"+country+\"/train/annotations/coco\"\n",
    "train_name = \"train_balance.json\"\n",
    "test_name = \"test_balance.json\"\n",
    "if not os.path.exists(save_path): \n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3364f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:01, 1036.38it/s]\n"
     ]
    }
   ],
   "source": [
    "coco_format={}\n",
    "coco_format['images']=[]\n",
    "coco_format['annotations']=[]\n",
    "\n",
    "category=[]\n",
    "\n",
    "total_n=0\n",
    "for idx,file_name in tqdm(enumerate(train)):\n",
    "    total_n+=1\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image_dic={}\n",
    "    image_dic['id']=idx\n",
    "    image_dic['width']=json_data[\"image\"][\"resolution\"][0]\n",
    "    image_dic['height']=json_data[\"image\"][\"resolution\"][1]\n",
    "    image_dic['file_name']=json_data[\"image\"][\"filename\"]\n",
    "    coco_format['images'].append(image_dic)\n",
    "\n",
    "\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        total_n+=1\n",
    "        if \"box\" in instance.keys(): # only bbox\n",
    "            annoation_dic={} \n",
    "            annoation_dic['id']=total_n\n",
    "            annoation_dic['image_id']=idx\n",
    "            annoation_dic['category_id']=category_list.index(instance[\"class\"])+1\n",
    "            annoation_dic['segmentation']=[[]]\n",
    "            \n",
    "            # x,y,w,h\n",
    "            temp=[]\n",
    "            temp.append(instance[\"box\"][0])\n",
    "            temp.append(instance[\"box\"][1])\n",
    "            temp.append(abs(instance[\"box\"][2] - instance[\"box\"][0]))\n",
    "            temp.append(abs(instance[\"box\"][3] - instance[\"box\"][1]))\n",
    "            annoation_dic['bbox']=temp\n",
    "            \n",
    "            annoation_dic['area']=temp[2]*temp[3]\n",
    "            annoation_dic['iscrowd']=0\n",
    "            coco_format['annotations'].append(annoation_dic)\n",
    "    \n",
    "# categories\n",
    "coco_format['categories']=category_dic_list\n",
    "\n",
    "#save json\n",
    "with open(os.path.join(save_path,train_name), 'w', encoding='utf-8') as make_file:\n",
    "\n",
    "    json.dump(coco_format, make_file, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c7b5315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "389it [00:00, 1819.03it/s]\n"
     ]
    }
   ],
   "source": [
    "coco_format={}\n",
    "coco_format['images']=[]\n",
    "coco_format['annotations']=[]\n",
    "\n",
    "category=[]\n",
    "\n",
    "total_n=0\n",
    "for idx,file_name in tqdm(enumerate(test)):\n",
    "    total_n+=1\n",
    "    with open(os.path.join(path,file_name), 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    image_dic={}\n",
    "    image_dic['id']=idx\n",
    "    image_dic['width']=json_data[\"image\"][\"resolution\"][0]\n",
    "    image_dic['height']=json_data[\"image\"][\"resolution\"][1]\n",
    "    image_dic['file_name']=json_data[\"image\"][\"filename\"]\n",
    "    coco_format['images'].append(image_dic)\n",
    "\n",
    "\n",
    "    for idy,instance in enumerate(json_data[\"annotations\"]):\n",
    "        total_n+=1\n",
    "        if \"box\" in instance.keys(): # only bbox\n",
    "            annoation_dic={} \n",
    "            annoation_dic['id']=total_n\n",
    "            annoation_dic['image_id']=idx\n",
    "            annoation_dic['category_id']=category_list.index(instance[\"class\"])+1\n",
    "            annoation_dic['segmentation']=[[]]\n",
    "            \n",
    "            # x,y,w,h\n",
    "            temp=[]\n",
    "            temp.append(instance[\"box\"][0])\n",
    "            temp.append(instance[\"box\"][1])\n",
    "            temp.append(abs(instance[\"box\"][2] - instance[\"box\"][0]))\n",
    "            temp.append(abs(instance[\"box\"][3] - instance[\"box\"][1]))\n",
    "            annoation_dic['bbox']=temp\n",
    "            \n",
    "            annoation_dic['area']=temp[2]*temp[3]\n",
    "            annoation_dic['iscrowd']=0\n",
    "            coco_format['annotations'].append(annoation_dic)\n",
    "    \n",
    "# categories\n",
    "coco_format['categories']=category_dic_list\n",
    "\n",
    "#save json\n",
    "with open(os.path.join(save_path,test_name), 'w', encoding='utf-8') as make_file:\n",
    "\n",
    "    json.dump(coco_format, make_file, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d411405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
